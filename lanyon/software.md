---
layout: page
title: Software
---

## GT Sophy
My current role allows to me to engineer the AI learning libraries that are used at [SonyAI](https://ai.sony) to train game AI. These were used to create the AI GT Sophy, which beat the best players in the world in the racing simulator Grand Turismo.

You can learn more about this system in the published [Nature Paper](https://www.nature.com/articles/s41586-021-04357-7).

## Autonomous delivery framework
I lead the design of a backend framework to connect and coordinate user requests as live commands to an autonomous delivery robot. It utilized various cloud technologies to connect a live, autonomous robots with users via a smart phone app.
This was part of project [SMADS](https://smads.netlify.app) which was centered around robot autonomy in an urban environment.

## Autonomous navigation controls
I've worked on navigation automation stack for indoor environments for a number of entities and platforms. This includes Universities and companies such as Diligent Robotics and Svenzva Robotics.

## Visual Music
Visual Music started as a commissioned art project which turned into a Web3 app. Originally started as a phyisical box to display _music_, **not** as a visualizer but as the sound waves itself.

### Hardware Box
The box and the electronics within are completely custom. It allows laser display of sound using high-baud galvonometers. Details about the concept generally can be found in the webapp link that follows.
![Revel: Repeatability](/public/seeingsound/boxes.jpg){: width="70%" }

### Web3 App
The web app [VisualMusic](https://visualmusic.app/demo) takes the same concept as the box, but displays it in a browser. However, much is planned for the web app, including a live, interative component with the physical laser box. The app uses blockchain to give artists ownership over tracks that they can develop specifically for display.

