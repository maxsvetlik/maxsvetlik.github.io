I")<p>While working as a Software Engineer at the <a href="http://sim.ece.utexas.edu/research.html">Socially Intelligent Machines Lab</a> I lead the software and hardware integration on a new socially capable robot. This included writing ROS wrappers for components with existing drivers, writing drivers from scratch for those that did not, and writing a technical manual for users of the platform. The robot is currently patent-pending.</p>

<p><a href="http://www.youtube.com/watch?v=p9QN0LiFrCc">
   <img src="https://img.youtube.com/vi/p9QN0LiFrCc/0.jpg" alt="Poli Video" style="width:55%; height:55%; margin-left: auto; margin-right:auto" />
</a></p>

<p>The design of the robotâ€™s outward facing appearance was carefully iteraterated, as the robot would be used specifically for human robot interaction research.<br />
Part of the aesthetic design I am most pleased with is the development of the socially expressive eye panel, which has been shown to be useful in non-verbally communicating intent, while users and passer-bys are charmed by the low-resolution LED display.</p>

<p>You can see the robot (without its protective breastplate) in the video above, and the open source software repository <a href="https://github.com/si-machines/poli2">here</a>. Overall the project was around 300,000 lines of code.</p>
:ET